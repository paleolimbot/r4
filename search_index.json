[
["index.html", "R in the CWRS Introduction", " R in the CWRS The R Programming Group at the CWRS 2017-09-05 Introduction TODO: write this section This course material was written using the bookdown package inside RStudio. Pages were generated using pandoc and gitbook. The source is available on github. "],
["basic-r.html", "Chapter 1 Basic R 1.1 Prerequisites 1.2 Expressions and Variables 1.3 Functions 1.4 Vectors 1.5 Indexing 1.6 Using the Script Editor 1.7 Excercises 1.8 Summary", " Chapter 1 Basic R When you open RStudio, you are presented with the ominous &gt; of the R console. By the end of this tutorial, hopefully that &gt; should fill you with a feeling of hope and opportunity, for magical things can happen when you type the right thing after the &gt;. This short introduction will get you started with the R console so that when we introduce more powerful functions, you can understand what R is doing at the base level! The tutorial is loosely based on the Workflow: basics tutorial in the free online book, R for Data Science. 1.1 Prerequisites To complete this tutorial, you will need R and RStudio installed, and RStudio open. If you can see the &gt; of the R console in the lower left part of your screen, you are good to go! The basic R console. 1.2 Expressions and Variables Let’s start with the basics. Try typing in something like this at the prompt: 1 + 1 ## [1] 2 2 * 5 ## [1] 10 5 ^ 2 ## [1] 25 2 * (5 + 1) ## [1] 12 As you can see, R works just like a calculator and evaluates all of these expressions just like you would expect. If we would like to save the result of one of these expressions we can assign that value to a variable like this: x &lt;- 1 + 1 Then, to view the value of x we can just type x at the console, and R will show us the value. x ## [1] 2 The &lt;- means “assign the value on the right to the variable on the left”. We can also use x in any expression and R will substitute its value in like this: x + 2 ## [1] 4 An expression is something that R can evaluate to produce a value, like 2+2 or x + 2. Any time you type this in the console without assigning it to a variable, R will print out the value. In fact, any time you type anything into the R console, R is evaluating that expression, which may or may not return a value. If there is no value returned, R won’t print anything when you press enter. So far we’ve just used numbers, but often we need to enter text into R. Whenever we do this, we surround the text in quotes, like this: mytext &lt;- &quot;I am text&quot; Text (called character vectors) are one of many data types available in R. 1.3 Functions A function is some kind of operation that takes one or more arguments (input values) and produces a return value (output value). The sqrt() function is a good example: sqrt(4) ## [1] 2 Here, 4 is an argument, and the function returns the square root of that, which is 2. Functions can take more arguments, like the max function: max(2, 6, 7, 2, 10) ## [1] 10 Here we are giving the max function 5 arguments, of which it returns the maximum. One other way we specify arguments is by keyword arguments, like in the paste function. paste(&quot;string1&quot;, &quot;string2&quot;, sep = &quot;_&quot;) ## [1] &quot;string1_string2&quot; The paste function takes its arguments and combines them using the sep that we specify, in this case &quot;_&quot;. The function returns this string. Many functions in R have many many arguments and usually we only want to modify one or two of interest to us. The format is always key=value, where key is the name of the keyword and value is some expression we would like to use as the value for that argument. R contains thousands of functions that do most of what you could possibly imagine with regards to data and statistics, but remembering which one you want and how to use it can be difficult. Luckily, RStudio makes it easy using tab autocompletion and easy access to help files. To autocomplete, start typing the name of the function and press the [Tab] key (or Ctrl+Space), and RStudio will helpfully provide you with suggestions. To access the documentation for a particular function, you can type ? in front of the function name and press return, and RStudio will open the help file for you if it exists. ?paste Will bring up the following: 1.3 Description Concatenate vectors after converting to character. 1.3 Usage paste (..., sep = &quot; &quot;, collapse = NULL) paste0(..., collapse = NULL) 1.3 Arguments … one or more R objects, to be converted to character vectors. sep a character string to separate the terms. Not NA_character_. collapse an optional character string to separate the results. Not NA_character_. Note that each of these arguments can be specified by keyword, and have default values that we can see in the usage section. The ... means that we can pass any number of arguments to the function. There’s too many functions in R to keep in your head at one time, so getting good at reading these help files is very useful! 1.4 Vectors So far we’ve just been dealing with single values like 2+2 or &quot;mystring&quot;, but the real power of R is that it can operate easily on large lists of data, so it makes sense that it provides us with an easy way to work with this data. These lists of data are called vectors, and we create them using the c function (c stands for concatenate, or join together). myvector &lt;- c(10, 9, 8, 7, 2) myvector ## [1] 10 9 8 7 2 Here the c function took our arguments of 10, 9, 8, 7, and 2, and returned a vector, which we assigned to the variable named myvector. When we evaluated myvector, it printed out the list of values it contained. Vectors don’t just have to contain numbers, they can contain strings as well. mytextvector &lt;- c(&quot;word1&quot;, &quot;word2&quot;, &quot;word3&quot;) mytextvector ## [1] &quot;word1&quot; &quot;word2&quot; &quot;word3&quot; Here the c function took our arguments and returned a vector of strings, which we assigned to the variable mytextvector. It is common to have to generate a vector of all the integer values between two numbers, so R provides a short form for this: 1:10 ## [1] 1 2 3 4 5 6 7 8 9 10 20:12 ## [1] 20 19 18 17 16 15 14 13 12 myothervector &lt;- 13:16 myothervector ## [1] 13 14 15 16 You can also use an expression on either side of the :, like this: (5^2):(3*10) ## [1] 25 26 27 28 29 30 start &lt;- 25 end &lt;- start + 5 start:end ## [1] 25 26 27 28 29 30 1.5 Indexing Now we’ve created vectors, but to get at what’s inside them we need to retrieve values using an index. We do this using square brackets like this: myvector &lt;- c(10, 9, 8, 7, 2) myvector[1] ## [1] 10 myvector[5] ## [1] 2 myvector[3] ## [1] 8 This code creates a vector, assigns it to the variable myvector, then retrieves the 1st, 5th, and 3rd value stored in that vector. If we would like multiple values from the vector, we can pass multiple values as indices, like this: myvector[c(1, 5, 3)] ## [1] 10 2 8 You’ll notice that the index that we’re using is actually a vector itself! I know, we’re using a vector to index a vector and it’s a little trippy, but it’s incredibly useful. You’ll remember that we can easily create vectors of sequential integers, which we can use to get a sequence of values from a vector by using it as an index. myvector[1:3] ## [1] 10 9 8 This would be equivalent to: myvector[c(1, 2, 3)] ## [1] 10 9 8 There is one other useful way to index a vector using a vector, which is to use a TRUE/FALSE vector. This is probably the most useful of the indexing methods, because it allows you to do things like: myvector[myvector &gt; 7] ## [1] 10 9 8 This works because myvector &gt; 7 is, itself, a TRUE/FALSE vector with the same length as myvector, indicating whether or not it is greater than 7 at any given position. myvector &gt; 7 ## [1] TRUE TRUE TRUE FALSE FALSE 1.6 Using the Script Editor In reality, very little of the code you type will be directly in the prompt. Instead, you will use RStudio’s script editor to run commands so that you can go back and edit them or run them from the beginning. To create a new R script, choose File, New File, and R script (you can also choose the little green “+” button at the top left of the console window). A blank R script should appear in a new tab. A new R script in the RStudio script editor. When you type a command in the editor and press enter, nothing happens! This is because the editor is meant to build script that contain multiple lines, unlike the console, which is meant to execute a single line at a time. To run a command you have typed in the script editor, press Ctrl+Enter (Command+Enter on a Mac). You can even select multiple lines, press Ctrl+Enter, and they will all run at once! You can also save the script and choose Source to run the whole thing. 1.7 Excercises To practice the basics of R, complete the very first swirl module, R Programming / Basic Building Blocks. To do this, you’ll need to install and load swirl by typing this at the R prompt: install.packages(&quot;swirl&quot;) library(swirl) swirl() You should get a friendly greeting that will prompt you to choose a course (you want number 1, “R Programming: The basics of programming in R”) and a module (you want number 1, “Basic Building Blocks”). 1.8 Summary In this lesson we covered expressions, variables, functions, vectors, and indexing, all of which will help you get the most out of the tutorials in this series. For more information, check out the Workflow: basics and Workflow: scripts tutorial in the free online book, R for Data Science. "],
["working-with-tables-using-the-tidyverse.html", "Chapter 2 Working with Tables using the Tidyverse 2.1 Prerequisites 2.2 Viewing a Data Frame 2.3 Selecting Columns 2.4 Filtering Rows 2.5 Selecting and Filtering 2.6 The Pipe (%&gt;%) 2.7 Summarising A Data Frame 2.8 Excercises 2.9 Summary", " Chapter 2 Working with Tables using the Tidyverse In this tutorial we will introduce the data frame, or the object type that R uses to store tables. Most of the data you will work with in R can be represented by a table (think an excel sheet), and one of the main advantages of using R is that the data frame is a powerful and intuitive interface for tabular data. In this tutorial we will use the tidyverse to manipulate and summarise tabular data. The tutorial is a companion to the Data transformation chapter in R for Data Science. 2.1 Prerequisites The prerequisites for this tutorial are tidyverse and rclimateca. If these packages aren’t installed, you’ll have to install them using install.packages(). install.packages(&quot;tidyverse&quot;) install.packages(&quot;rclimateca&quot;) Load the packages when you’re done! If there are errors, you may have not installed the above packages correctly! library(tidyverse) ## Loading tidyverse: ggplot2 ## Loading tidyverse: tibble ## Loading tidyverse: tidyr ## Loading tidyverse: readr ## Loading tidyverse: purrr ## Loading tidyverse: dplyr ## Conflicts with tidy packages ---------------------------------------------- ## filter(): dplyr, stats ## lag(): dplyr, stats library(rclimateca) Finally, you will need to obtain the sample data using the getClimateData() function in the rclimateca package. Copy/paste the statement below to load the sample data for this tutorial. climate_data &lt;- getClimateData(c(27141, 6354), nicenames = TRUE) It’s worth mentioning a little bit about what this data frame contains, since we’ll be working with it for the rest of this tutorial. Each row contains a number of parameters that are available on a monthly basis from two Environment Canada climate stations (Kentville Agricultural Research Station is 27141; Greenwood Station is 6354). The stationid column identifies where the values were measured, the year and month column identify when the values were measured, and the rest of the columns contain the measured values. For each measured value column, there is a flag column that gives additional information about the measurement (for the most part, we will ignore these columns). The only column names that are slightly cryptic are extrmaxtemp and extrmintemp, which are the extreme maximum and minimum temperatures measured in that month, respectively. 2.2 Viewing a Data Frame The variable we have just created (climate_data) is a data frame, which is a table of values much like you would find in a spreadsheet. Each column in the data frame represents a variable (in this case, the year and month where each observation was measured, the mean temperature, total precipitation, and many others), and each row in the table represents an observation (for example, the mean temperature and total precipitation in May of 1999 at Greenwood). In RStudio’s “Environment” tab (usually at the top right of the screen), you should see a variable called climate_data in the list. You can inspect it by clicking on the variable name, after which a tab will appear displaying the contents of the variable you just loaded. Clicking the little arrow to the left of the name will display the structure of the data frame, including the column names and some sample values. You can also do both of these things using the R commands View() and str(), respectively. Also useful is the head() function, which will display the first few rows of a data frame. View(climate_data) # will display a graphic table browser str(climate_data) # will display a text summary of the object ## &#39;data.frame&#39;: 997 obs. of 27 variables: ## $ stationid : num 27141 27141 27141 27141 27141 ... ## $ datetime : chr &quot;1996-07&quot; &quot;1996-08&quot; &quot;1996-09&quot; &quot;1996-10&quot; ... ## $ year : int 1996 1996 1996 1996 1996 1996 1997 1997 1997 1997 ... ## $ month : int 7 8 9 10 11 12 1 2 3 4 ... ## $ meanmaxtemp : num 23.8 24.8 18.8 12.3 6.1 4.8 -0.8 -0.2 1.1 7.1 ... ## $ meanmaxtempflag : chr &quot;&quot; &quot;&quot; &quot;&quot; &quot;&quot; ... ## $ meanmintemp : num 14.4 13.8 11.3 3.7 0 -1.9 -9.5 -8.4 -6.9 -1.2 ... ## $ meanmintempflag : chr &quot;&quot; &quot;&quot; &quot;&quot; &quot;&quot; ... ## $ meantemp : num 19.1 19.4 15.1 8 3 1.5 -5.2 -4.3 -2.9 2.9 ... ## $ meantempflag : chr &quot;&quot; &quot;&quot; &quot;&quot; &quot;&quot; ... ## $ extrmaxtemp : num 29.6 31.6 27.6 20.4 19 15.5 10.9 10.6 10 14.4 ... ## $ extrmaxtempflag : chr &quot;&quot; &quot;&quot; &quot;&quot; &quot;&quot; ... ## $ extrmintemp : num 10.7 8.5 3.7 -1.7 -8.7 -15.7 -20.9 -17.1 -17 -11.7 ... ## $ extrmintempflag : chr &quot;S&quot; &quot;&quot; &quot;&quot; &quot;&quot; ... ## $ totalrain : num NA NA NA NA NA NA NA NA NA NA ... ## $ totalrainflag : chr NA NA NA NA ... ## $ totalsnow : num NA NA NA NA NA NA NA NA NA NA ... ## $ totalsnowflag : chr NA NA NA NA ... ## $ totalprecip : num 147.5 24.4 260.7 95.5 91.3 ... ## $ totalprecipflag : chr &quot;&quot; &quot;&quot; &quot;&quot; &quot;&quot; ... ## $ snowgrndlastday : int 0 0 0 0 NA 0 2 4 11 0 ... ## $ snowgrndlastdayflag: chr &quot;&quot; &quot;&quot; &quot;&quot; &quot;&quot; ... ## $ dirofmaxgust : int NA NA NA NA NA NA NA NA NA NA ... ## $ dirofmaxgustflag : chr NA NA NA NA ... ## $ spdofmaxgust : chr NA NA NA NA ... ## $ spdofmaxgustflag : chr NA NA NA NA ... ## $ parseddate : Date, format: &quot;1996-07-01&quot; &quot;1996-08-01&quot; ... head(climate_data) ## # A tibble: 6 x 27 ## stationid datetime year month meanmaxtemp meanmaxtempflag meanmintemp ## * &lt;dbl&gt; &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 27141 1996-07 1996 7 23.8 14.4 ## 2 27141 1996-08 1996 8 24.8 13.8 ## 3 27141 1996-09 1996 9 18.8 11.3 ## 4 27141 1996-10 1996 10 12.3 3.7 ## 5 27141 1996-11 1996 11 6.1 0.0 ## 6 27141 1996-12 1996 12 4.8 -1.9 ## # ... with 20 more variables: meanmintempflag &lt;chr&gt;, meantemp &lt;dbl&gt;, ## # meantempflag &lt;chr&gt;, extrmaxtemp &lt;dbl&gt;, extrmaxtempflag &lt;chr&gt;, ## # extrmintemp &lt;dbl&gt;, extrmintempflag &lt;chr&gt;, totalrain &lt;dbl&gt;, ## # totalrainflag &lt;chr&gt;, totalsnow &lt;dbl&gt;, totalsnowflag &lt;chr&gt;, ## # totalprecip &lt;dbl&gt;, totalprecipflag &lt;chr&gt;, snowgrndlastday &lt;int&gt;, ## # snowgrndlastdayflag &lt;chr&gt;, dirofmaxgust &lt;int&gt;, dirofmaxgustflag &lt;chr&gt;, ## # spdofmaxgust &lt;chr&gt;, spdofmaxgustflag &lt;chr&gt;, parseddate &lt;date&gt; 2.3 Selecting Columns One way to subset climate_data is to subset by column, for which we will use the select() function. For example, we may only be interested in the mean temperature information, represented by the columns stationid, year, month, and meantemp. mean_temp_data &lt;- select(climate_data, stationid, year, month, meantemp) The first argument to the select() function is the original data frame (in this case, climate_data), and the remaining arguments are the names of the columns to be selected. To select the stationid, year, month, meantemp and totalprecip columns, you would use the following R command: temp_precip_data &lt;- select(climate_data, stationid, year, month, meantemp, totalprecip) 2.3.1 Excercises Use View(), str(), and head() to preview the two data frames we just created. Do they have the columns you would expect? Use select() to select stationid, year, month, and all of the columns containing temperature values, and assign it to the variable temp_data. 2.4 Filtering Rows Another way to subset climate_data is by filtering rows using column values, similar to the filter feature in Microsoft Excel. This is done using the filter() function. For example, we may only be interested in July temperature for the two stations. july_data &lt;- filter(climate_data, month == 7) Just like select(), the first argument to filter() is the original data frame, and the subsequent arguments are the conditions that each row must satisfy in order to be included in the output. Column values are referred to by the column name (in the above example, month), so to include all rows where the value in the month column is 7, we use month == 7. Passing multiple conditions means each row must satisfy all of the conditions, such that to obtain the data for July of 1999, we can use the following call to filter(): july_1999_data &lt;- filter(climate_data, month == 7, year == 1999) It is very important that there are two equals signs within filter()! The == operator tests for equality (e.g. (2 + 2) == 4), whereas the = operator assigns a value or passes a named argument to a function, which is not what you’re trying to do within filter(). Other common operators that are useful within filter are != (not equal to), &gt; (greater than), &lt; (less than), &gt;= (greater than or equal to), &lt;= (less than or equal to), and %in% (tests if the value is one of several values). Using these, we could find out which observations had mean temperatures that were below freezing: freezing_observations &lt;- filter(climate_data, meantemp &lt; 0) We could also find which observations occurred during the summer months (May, June, July, or August): summer_data &lt;- filter(climate_data, month %in% c(5, 6, 7, 8)) 2.4.1 Exercises Use View(), str(), and head() to preview the data frames we just created. Do they have the rows you would expect? Use filter() to find observations from the month of December where the mean temperature was above freezing. Are there any observations from the month of January where the mean temperature was below freezing? Filter climate_data to include only observations from the months of December, January, February, and March and assign it to a variable name of your choosing. 2.5 Selecting and Filtering Often we need to use both select() and filter() to obtain the desired subset of a data frame. To do this, we need to pass the result of select() to filter(), or the result of filter() to select. For example, we could create a data frame of mean temperature observations from the month of July one of two ways (you’ll recall that we selected temperature columns in the data frame mean_temp_data, and we filtered for the month of July in the data frame july_data): july_temp &lt;- filter(mean_temp_data, month == 7) july_temp2 &lt;- select(july_data, stationid, year, month, meantemp) 2.5.1 Exercises Inspect july_temp and july_temp2 using View(), str(), and head(). Are they identical? Create a data frame of July total precipitation data and give it a variable name of your choosing. Do this by using select() followed by filter(), then using filter() followed by select(). Inspect the output to ensure the data frames are identical. 2.6 The Pipe (%&gt;%) There is an easier way! Instead of creating intermediary variables every time we want to subset a data frame using select() and filter(), we can use the pipe operator (%&gt;%) to pass the result of one function call to another. Thus, creating our july_temp data frame from above becomes one line with one variable assignment instead of two. july_temp3 &lt;- climate_data %&gt;% filter(month == 7) %&gt;% select(stationid, year, month, meantemp) What %&gt;% does is pass the left side into the first argument of the function call on the right side. Thus, filter(climate_data, month == 7) becomes climate_data %&gt;% filter(month ==7). When using the tidyverse family of packages, you should use the pipe as often as possible! It usually makes for more readable, less error-prone code, and reduces the number of temporary variables you create that clutter up your workspace. When using filter() and select() with other tidyverse manipulations like arrange(), group_by(), summarise(), and mutate(), the pipe becomes indispensable. 2.6.1 Exercises Inspect july_temp3 to ensure it is identical to july_temp. Create a data frame of July total precipitation data using climate_data, filter(), select(), and %&gt;%. Is it identical to the data frame you created in the exercise above? 2.7 Summarising A Data Frame So far we have looked at subsets of climate_data, but what if we want yearly averages instead of monthly averages? Using the tidyverse, we can group_by() the stationid and year column, and summarise(): climate_data %&gt;% group_by(stationid, year) %&gt;% summarise(mean_temp = mean(meantemp)) ## # A tibble: 84 x 3 ## # Groups: stationid [?] ## stationid year mean_temp ## &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; ## 1 6354 1942 NA ## 2 6354 1943 6.150000 ## 3 6354 1944 6.933333 ## 4 6354 1945 6.800000 ## 5 6354 1946 6.850000 ## 6 6354 1947 7.425000 ## 7 6354 1948 6.208333 ## 8 6354 1949 7.883333 ## 9 6354 1950 6.758333 ## 10 6354 1951 7.983333 ## # ... with 74 more rows Here group_by() gets a list of columns, for which each unique combination of values will get one row in the output. summarise() gets a list of expressions that are evaluated for every unique combination of values defined by group_by() (e.g., mean_temp is the mean() of the meantemp column for each station, for each year). Often, we want to include a number of summary columns in the output, which we can do by pasing more expressions to summarise(): climate_data %&gt;% group_by(stationid, year) %&gt;% summarise(mean_temp = mean(meantemp), max_temp = max(extrmaxtemp), min_temp = min(extrmintemp)) ## # A tibble: 84 x 5 ## # Groups: stationid [?] ## stationid year mean_temp max_temp min_temp ## &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 6354 1942 NA NA NA ## 2 6354 1943 6.150000 32.8 -27.8 ## 3 6354 1944 6.933333 37.2 -21.7 ## 4 6354 1945 6.800000 32.8 -21.7 ## 5 6354 1946 6.850000 33.3 -25.6 ## 6 6354 1947 7.425000 33.9 -26.1 ## 7 6354 1948 6.208333 34.4 -30.0 ## 8 6354 1949 7.883333 35.6 -21.7 ## 9 6354 1950 6.758333 32.2 -25.0 ## 10 6354 1951 7.983333 31.7 -26.7 ## # ... with 74 more rows You will notice that in 1942 the mean temperature appears to be NA, or missing. This is because R propogates missing values unless you explicitly tell it not to. To fix this, you could replace mean(meantemp) with mean(meantemp, na.rm = TRUE). Other useful functions to use inside summarise() include mean(), median(), sd(), sum(), min(), and max(). These all take a vector of values and produce a single aggregate value suitable for use in summarise(). One special function, n(), you can use (with no arguments) inside summarise() to tell you how many observations were aggregated to produce the values in that row. climate_data %&gt;% group_by(stationid, year) %&gt;% summarise(mean_temp = mean(meantemp, na.rm = TRUE), max_temp = max(extrmaxtemp, na.rm = TRUE), min_temp = min(extrmintemp, na.rm = TRUE), n = n()) ## # A tibble: 84 x 6 ## # Groups: stationid [?] ## stationid year mean_temp max_temp min_temp n ## &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; ## 1 6354 1942 -1.700000 21.1 -21.1 12 ## 2 6354 1943 6.150000 32.8 -27.8 12 ## 3 6354 1944 6.933333 37.2 -21.7 12 ## 4 6354 1945 6.800000 32.8 -21.7 12 ## 5 6354 1946 6.850000 33.3 -25.6 12 ## 6 6354 1947 7.425000 33.9 -26.1 12 ## 7 6354 1948 6.208333 34.4 -30.0 12 ## 8 6354 1949 7.883333 35.6 -21.7 12 ## 9 6354 1950 6.758333 32.2 -25.0 12 ## 10 6354 1951 7.983333 31.7 -26.7 12 ## # ... with 74 more rows Unsurprisingly, there are twelve observations per year, since there are twelve rows (one per month) in our original data frame. It’s always a good idea to include n() inside summarise(), if nothing else as a check to make sure you’ve used group_by() with the correct columns. 2.8 Excercises Assign the data frame we just created to a variable, and inspect it using View() and str(). Which years were the warmest? Which years were the coldest? Create a similar data frame to the one we just created but with precipitation. In which years did the most precipitation fall? (Hint: you will need to use the sum() function) Most of the data are from Greenwood (stationid 6354), with fewer years from Kentville (stationid 27141). How many years are available for each station, and what is the range of years where data is available for each station? (Hint: you will need to group_by(stationid)) 2.9 Summary In this tutorial we introduced the use of select(), filter() and the pipe (%&gt;%). We also used group_by() and summarise() to provide summary statistics from a data frame. These functions are the building blocks of other powerful tools in the tidyverse. "],
["creating-visualizations-using-ggplot.html", "Chapter 3 Creating Visualizations using ggplot 3.1 Prerequisites 3.2 Using ggplot 3.3 Summary", " Chapter 3 Creating Visualizations using ggplot Intro 3.1 Prerequisites The prerequisites for this tutorial are tidyverse and rclimateca. If these packages aren’t installed, you’ll have to install them using install.packages(). install.packages(&quot;tidyverse&quot;) install.packages(&quot;rclimateca&quot;) Load the packages when you’re done! If there are errors, you may have not installed the above packages correctly! library(tidyverse) library(rclimateca) Finally, you will need to obtain the sample data using the getClimateData() function in the rclimateca package. Copy/paste the statement below to load the sample data for this tutorial. climate_data &lt;- getClimateData(c(27141, 6354), year = 2000:2003, nicenames = TRUE) %&gt;% left_join(ecclimatelocs %&gt;% select(station_name = Name, stationid = `Station ID`), by = &quot;stationid&quot;) It’s worth mentioning a little bit about what this data frame contains, since we’ll be working with it for the rest of this tutorial. Each row contains a number of parameters that are available on a monthly basis from two Environment Canada climate stations (Kentville Agricultural Research Station is 27141; Greenwood Station is 6354). The stationid column identifies where the values were measured, the year and month column identify when the values were measured, and the rest of the columns contain the measured values. For each measured value column, there is a flag column that gives additional information about the measurement (for the most part, we will ignore these columns). The only column names that are slightly cryptic are extrmaxtemp and extrmintemp, which are the extreme maximum and minimum temperatures measured in that month, respectively. 3.2 Using ggplot The Grammar of Graphics (the “gg” in “ggplot”) is a way of describing a graphic that is derived from data, which in R is done using the ggplot() function and its many friends. Unlike other plotting functions, ggplot() builds graphics from the data up (rather than starting with a template of a graphic and working backward). We will start with an example: ggplot(climate_data, aes(x = meantemp, y = totalprecip, colour = station_name)) + geom_point() ## Warning: Removed 2 rows containing missing values (geom_point). 3.3 Summary Tutorial summary "],
["preparing-and-loading-your-data-into-r.html", "Chapter 4 Preparing and Loading your data into R 4.1 Prerequisites 4.2 Preparing data 4.3 Loading data 4.4 Cleaning data 4.5 Summary", " Chapter 4 Preparing and Loading your data into R Intro 4.1 Prerequisites The prerequisites for this tutorial are tidyverse. If this package isn’t installed, you’ll have to install it using install.packages(). install.packages(&quot;tidyverse&quot;) Load the packages when you’re done! If there are errors, you may have not installed the above packages correctly! library(tidyverse) Finally, you will need to obtain the sample data… 4.2 Preparing data 4.3 Loading data 4.4 Cleaning data 4.5 Summary Tutorial summary "],
["using-rstudio-projects.html", "Chapter 5 Using RStudio Projects 5.1 Prerequisites 5.2 Projects 5.3 Creating a new project 5.4 Organizing a project 5.5 Why use a project? 5.6 Summary", " Chapter 5 Using RStudio Projects Even if you know how to code in R, you will still need a strategy of how to organize your data, code, and output to take advantage of all the things R and RStudio have to offer. This tutorial suggests one way of doing this, with the take home message that you should stay organized! 5.1 Prerequisites The only prerequisite for this tutorial is RStudio. This tutorial draws heavily on the Projects chapter and the Scripts chapter in R for Data Science by Hadley Wickham. 5.2 Projects Projects are a notion in RStudio that let you keep a set of related data and scripts organized in a single directory. R scripts are rarely useful without data files, and data files are rarely useful on their own when using R for data analyis. Furthermore, the figures and tables you generate using R are only replicable if you know which script created them! An RStudio project lets you keep your data, scripts, and output in the same working directory, so that it is easy to refer to your data from your files, and easy to know which scripts generated your analysis. 5.3 Creating a new project To create a new project, chose New project… from the File menu, or click on the little RStudio icon in the upper right side of your screen to open the New project dialog. The project menu in RStudio is located in the upper right corner of the screen. When you have created more projects, you can easily switch between them here. This will direct you to a dialog that gives you some options about how to create your RStudio project. If you already have a folder that contains your scripts and/or data, you can use the Existing Directory option to turn that directory into a project. To create a brand new directory that is an RStudio project, choose the New Directory option. This will give you another menu, from which you’ll want to choose Empty Project. This will give you a window with a few options about where to create your project. Creating an RStudio project requires a directory name and a place where that directory lives. Name the project something descriptive and put it somwhere you can find it! The Desktop is not a bad place to start (you can move projects around after you’ve created them). 5.4 Organizing a project Most projects have at least three components: data, scripts, and output (once you get to using R Markdown you might have a fourth, documents). A well-organized project has defined places where these things live. I tend to put raw data (data that I have never touched, which usually means it is from an instrument or the internet or from somebody else’s spreadsheet) in a folder called raw_data/, and cleaned data in a folder called data/. Scripts (.R files) can live in a folder called scripts/, and output can live in a folder called output/ or figures/. R Markdown files (documents) need to live in the main project directory for a very good reason that you will learn when we get to using R Markdown. The point is not that you need to or should have specific folders, but that it is clear to you and others where to look for the various components of your project. A directory structure for a recent project collecting Halifax Water DOC measurements. The raw data folder contains an excel sheet from Halifax Water, and the clean_data.R script reads the excel sheet and generates halifax_wq.csv, which is read by all the scripts that do analysis and generate figures within the project. 5.5 Why use a project? The main advantage of using a project is that the working directory when you open one is automatically set to the directory of the project. This means that you never have to call setwd(), since your data always lives fairly close to your R script. In the above example of a recent RStudio project, hw_toc_plot.R reads in halifax_wq.csv using the command read_csv(&quot;data/halifax_wq.csv&quot;). No matter where the project lives on the computer (or indeed, whose computer the project lives on), this script can remain unchanged. This gives you the freedom to move the project folder about your computer, or to have it live somewhere like Dropbox or GitHub such that the project can be shared with others. 5.6 Summary This tutorial suggested one method of organizing R scripts and data to leverage the full potential of R and RStudio. Projects are an easy way to collect data, scripts, and output together in the same folder so that output can be replicated and analysis in scripts can be easily regenerated by yourself and others. "],
["computing-statistics-in-r.html", "Chapter 6 Computing statistics in R 6.1 Prerequisites 6.2 Terminology 6.3 Testing for Normality 6.4 Correlation and Linear Regression 6.5 Significant differences 6.6 Summary", " Chapter 6 Computing statistics in R Intro 6.1 Prerequisites The prerequisites for this tutorial are the tidyverse and broom packages. If these packages aren’t installed, you’ll have to install them using install.packages(). install.packages(&quot;tidyverse&quot;) # will also install the broom package Load the packages when you’re done! If there are errors, you may have not installed the above packages correctly! library(tidyverse) library(rclimateca) library(broom) Finally, you will need to obtain the sample data… climate_data &lt;- getClimateData(c(27141, 6354), year = 2000:2003, nicenames = TRUE) %&gt;% left_join(ecclimatelocs %&gt;% select(station_name = Name, stationid = `Station ID`), by = &quot;stationid&quot;) %&gt;% select(station_name, year, month, everything()) %&gt;% select(-ends_with(&quot;flag&quot;), -parseddate, -datetime, -stationid) 6.2 Terminology 6.2.1 Grouping Variables Many statistical test functions in R use a formula to specify a value column and a grouping column for a test using a data frame as input. This is usually a column that contains data labels like “group1”, “group1”, “group1”, “group2”, “group2”, etc., whose values divide observations into groups for which we want to test significance. In our sample data frame climate_data, these variables are station_name, year, month. The other variables represent measured values, whereas the grouping variables give context to each row. The formula used as input to statistical test functions is generally in the form measure_var ~ grouping_var, where measure_var and grouping_var are columns in a data frame. Sometimes it is necessary to use column names as grouping variables. In the case of the climate_data data frame, one might want to test whether the mean monthly temperature (meantemp) is significantly different than the extreme maximum monthly temperature (extrmaxtemp). Because these values are stored in two columns, there is no grouping variable that can separate these two sets of observations. This operation is possible using the gather() function. climate_data_mean_max_temp &lt;- climate_data %&gt;% select(station_name, year, month, meantemp, extrmaxtemp) %&gt;% gather(meantemp, extrmaxtemp, key = &quot;temperature_type&quot;, value = &quot;temp&quot;) climate_data_mean_max_temp ## # A tibble: 192 x 5 ## station_name year month temperature_type temp ## &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 KENTVILLE CDA CS 2000 1 meantemp -4.2 ## 2 KENTVILLE CDA CS 2000 2 meantemp -2.6 ## 3 KENTVILLE CDA CS 2000 3 meantemp 1.6 ## 4 KENTVILLE CDA CS 2000 4 meantemp 6.4 ## 5 KENTVILLE CDA CS 2000 5 meantemp 10.0 ## 6 KENTVILLE CDA CS 2000 6 meantemp 16.4 ## 7 KENTVILLE CDA CS 2000 7 meantemp 18.8 ## 8 KENTVILLE CDA CS 2000 8 meantemp 19.2 ## 9 KENTVILLE CDA CS 2000 9 meantemp 14.6 ## 10 KENTVILLE CDA CS 2000 10 meantemp 9.9 ## # ... with 182 more rows In the resulting data frame, the temperature_type column will contain the values “meantemp” and “extrmaxtemp”, which can be used as a grouping variable in a statistical test function. When using gather(), it is important to select only the relevant variables using select() first. 6.2.2 Paired Values Some statistical tests are only possible or are preferable with paired values, or values that are stored in two columns in a data frame (i.e., part of the same observation). The example above of testing whether the mean monthly temperature (meantemp) is significantly different than the extreme maximum monthly temperature (extrmaxtemp) could also be done pairwise, in which case the original data is already in the correct format for the test. Sometimes the data is provided in a form where there is a grouping variable, and measured values are in the same column (this is the result of the above example where we converted meantemp and extrmaxtemp into a grouping variable and a measured variable). We can transform a grouping variable and a measured variable into paired observations using the spread() function. climate_data_mean_max_temp %&gt;% spread(key = temperature_type, value = temp) ## # A tibble: 96 x 5 ## station_name year month extrmaxtemp meantemp ## * &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 GREENWOOD A 2000 1 18.0 -4.4 ## 2 GREENWOOD A 2000 2 17.8 -3.1 ## 3 GREENWOOD A 2000 3 17.9 2.0 ## 4 GREENWOOD A 2000 4 20.0 6.4 ## 5 GREENWOOD A 2000 5 21.3 10.4 ## 6 GREENWOOD A 2000 6 31.8 16.2 ## 7 GREENWOOD A 2000 7 29.4 19.0 ## 8 GREENWOOD A 2000 8 29.0 18.8 ## 9 GREENWOOD A 2000 9 31.0 14.1 ## 10 GREENWOOD A 2000 10 21.9 9.2 ## # ... with 86 more rows In the resulting data frame, the values that were in temperature_type are now column names, and the qualifying variables station_name, year, and month are used to identify unique observations that are paired with one another. 6.2.3 Independent Observations …don’t have a good explanation for this. 6.2.4 Graphical Test autocorrelation? 6.3 Testing for Normality Some tests (notably the t-test, the ANOVA test, and the Pearson coefficient) require that the input values are normally distributed. For small amounts of replicate samples, this is generally a good assumption, however larger samples whose distribution cannot be assumed require a test for normality. One such test is the Shapiro-Wilk test, which is described below. 6.3.1 Test Data The test for normality requires a data frame with one column that contains the values that should be normally distributed. In our example, we will test whether or not mean monthly temperature is normally distributed, and whether or not total montly precipitation is normally distributed. It is also good practice to keep qualifying variables that give context to each observation. normal_test_data &lt;- climate_data %&gt;% select(station_name, year, month, meantemp, totalprecip) normal_test_data ## # A tibble: 96 x 5 ## station_name year month meantemp totalprecip ## &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 KENTVILLE CDA CS 2000 1 -4.2 182.2 ## 2 KENTVILLE CDA CS 2000 2 -2.6 10.7 ## 3 KENTVILLE CDA CS 2000 3 1.6 116.4 ## 4 KENTVILLE CDA CS 2000 4 6.4 89.1 ## 5 KENTVILLE CDA CS 2000 5 10.0 58.0 ## 6 KENTVILLE CDA CS 2000 6 16.4 46.0 ## 7 KENTVILLE CDA CS 2000 7 18.8 72.4 ## 8 KENTVILLE CDA CS 2000 8 19.2 36.6 ## 9 KENTVILLE CDA CS 2000 9 14.6 58.4 ## 10 KENTVILLE CDA CS 2000 10 9.9 197.6 ## # ... with 86 more rows 6.3.2 Graphical Test The graphical test for a normality test is a histogram. ggplot(normal_test_data, aes(x = meantemp)) + geom_histogram(bins = 30) ## Warning: Removed 1 rows containing non-finite values (stat_bin). A historgram of a normally distributed variable should be symmetrical about its mean, like the histogram shown below: set.seed(300) normal_random_data &lt;- tibble(normal_random_data = rnorm(n = 100, mean = 0, sd = 1)) ggplot(normal_random_data, aes(x = normal_random_data)) + geom_histogram(bins = 30) A histogram of a normally distributed variable generally isn’t a perfect bell curve (especially when there are few data points), but should show some evidence of symmetry about the mean value. 6.3.3 Statistical Test Testing for normality in R involves a call to shapiro.test(), followed by a call to tidy() in the broom package to view the results in the form of a data frame. shapiro.test(normal_test_data$meantemp) %&gt;% tidy() ## # A tibble: 1 x 3 ## statistic p.value method ## &lt;dbl&gt; &lt;dbl&gt; &lt;fctr&gt; ## 1 0.9358426 0.0001631647 Shapiro-Wilk normality test A low p.value indicates that there is evidence to reject the notion that the input data are sampled from a normally distributed population. You will have to pick a level of significance (\\(\\alpha\\)) as a threshold, usually 0.05 or 0.01, under which the p-value will indicate the sample was drawn from a non-normal distribution. In our example, the mean montly temperature was shown to be non-normally distributed (p&lt;0.001). In the case of our normal random data, the p-value is quite high (p=0.72), suggesting that the data were sampled from a normally distributed population. shapiro.test(normal_random_data$normal_random_data) %&gt;% tidy() ## # A tibble: 1 x 3 ## statistic p.value method ## &lt;dbl&gt; &lt;dbl&gt; &lt;fctr&gt; ## 1 0.9907158 0.7223313 Shapiro-Wilk normality test 6.4 Correlation and Linear Regression Tests for correlation of two variables test whether or not a relationship exists between the two variables (i.e., can any of the variance of one variable be explained by variance in the other). This is often done to test association between two parameters when these measurements are paired. In our example, we will test the corellation between mean monthly temperature and total monthly precipitation, to ascertain whether or not a statistically significant relationship exists between the two. 6.4.1 Test Data Correlation tests all require a data frame with one column for the x variable and one column for the y variable. It is often useful to keep other qualifying variables that give context to each observation, but are not required by the test. In our case, the x variable will be meantemp and the y variable will be totalprecip. correlation_test_data &lt;- climate_data %&gt;% select(station_name, year, month, meantemp, totalprecip) correlation_test_data ## # A tibble: 96 x 5 ## station_name year month meantemp totalprecip ## &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 KENTVILLE CDA CS 2000 1 -4.2 182.2 ## 2 KENTVILLE CDA CS 2000 2 -2.6 10.7 ## 3 KENTVILLE CDA CS 2000 3 1.6 116.4 ## 4 KENTVILLE CDA CS 2000 4 6.4 89.1 ## 5 KENTVILLE CDA CS 2000 5 10.0 58.0 ## 6 KENTVILLE CDA CS 2000 6 16.4 46.0 ## 7 KENTVILLE CDA CS 2000 7 18.8 72.4 ## 8 KENTVILLE CDA CS 2000 8 19.2 36.6 ## 9 KENTVILLE CDA CS 2000 9 14.6 58.4 ## 10 KENTVILLE CDA CS 2000 10 9.9 197.6 ## # ... with 86 more rows 6.4.2 Graphical Test A graphical test of the correlation of two variables is a biplot with one variable on the x-axis, and one variable on the y-axis. The variable on the x-axis should be the indepenent variable for the purposes of the test. This will look something like ggplot(my_data_frame, x = independent_var, y = dependent_var) followed by geom_point(). You can add a linear regression to the plot using stat_smooth(method = lm). This will add the best-fit line whose slope and intercept we will calculate in the next section. ggplot(correlation_test_data, aes(x = meantemp, y = totalprecip)) + geom_point() + stat_smooth(method = lm) ## Warning: Removed 2 rows containing non-finite values (stat_smooth). ## Warning: Removed 2 rows containing missing values (geom_point). Based on inspection of the biplot, you should be able to have a hunch as to whether or not a linear relationship exists between the two variables. In our case, it looks like there is a weak negative correlation between mean temperature and total preciptiation (i.e., the higher the mean temperature for a given month, the lower the total precipitation for the same month). 6.4.3 The Pearson product-moment correlation coefficient (r) The Pearson product-moment correlation coefficient (usually known as the r value) is a test of how well a line of best fit is able to model the data (generally a standard least-squares linear regression). The coefficient ranges from -1 (perfect negative linear relationship) to +1 (perfect positive linear relationship). Generally the square of this value is reported (r2), and can be interpreted as “xx % of the variance in y_variable can be explained by the variance in x_variable”. There is no statistical way to test how good the linear relationship is, but it is possible to test that the coefficient is not equal to zero (i.e., it is possible to reject the notion that there x_variable and y_variable have no linear relationship). 6.4.3.1 Assumptions The Pearson product-moment correlation coefficient assumes that x_variable and y_variable are normally distributed. 6.4.3.2 Statistical Test Calculating the r value and associated p-value involves a call to cor.test() with method = &quot;pearson&quot;, followed by a call to tidy() in the broom package to get the test results in the form of a data frame. cor.test(~totalprecip + meantemp, data = correlation_test_data, method = &quot;pearson&quot;) %&gt;% tidy() ## # A tibble: 1 x 8 ## estimate statistic p.value parameter conf.low conf.high ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 -0.3043945 -3.0651 0.002855764 92 -0.4775578 -0.1084673 ## # ... with 2 more variables: method &lt;fctr&gt;, alternative &lt;fctr&gt; The estimate column contains the r value, which you could square to get the r2 value. The p.value column contains the p-value, which represents the probability that the two variables have no linear relationship. In our case, totalprecip and meantemp have a significant negative linear relationship (p=0.003). 6.4.4 Spearman \\(\\rho\\) or rs The Spearman correlation coefficient (abbreviated \\(\\rho\\) or rs) is a test of a one-to-one relationship between x_variable and y_variable, not necessarily linear. The test uses ranked values for x_variable and y_variable, so outliers are less of an issue than they are with the Pearson coefficient. Similar to the Perason coefficient, the rs value varies from -1 (a perfect one-to-one negative relationship) to 1 (a perfect one-to-one positive relationship). Similar to the Pearson coefficient, it is only possible to test that the value is not equal to zero (i.e., i.e., it is possible to reject the notion that there x_variable and y_variable have no one-to-one relationship). 6.4.4.1 Assumptions The Spearman correlation coefficient does not make any assumptions about the distribution of x_variable or y_variable. 6.4.4.2 Statistical Test Calculating the rs value and associated p-value involves a call to cor.test() with method = &quot;spearman&quot;, followed by a call to tidy() in the broom package to get the test results in the form of a data frame. cor.test(~totalprecip + meantemp, data = correlation_test_data, method = &quot;spearman&quot;) %&gt;% tidy() ## Warning in cor.test.default(x = c(182.2, 10.7, 116.4, 89.1, 58, 46, 72.4, : ## Cannot compute exact p-value with ties ## # A tibble: 1 x 5 ## estimate statistic p.value method ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;fctr&gt; ## 1 -0.3806479 191102.4 0.000153924 Spearman&#39;s rank correlation rho ## # ... with 1 more variables: alternative &lt;fctr&gt; The estimate column contains the rs value, and the p.value column contains the p-value, which represents the probability that the two variables are not correlated. In our case, totalprecip and meantemp have a significant negative relationship (p&lt;0.001). 6.4.5 Linear Regression Whereas a Pearson coefficient is meant to assess the quality of a linear relationship, linear regression is meant to determine the slope and intercept of that relationship in the form \\(y = mx + b\\), where \\(y\\) is y_variable, and x is x_variable. By obtaining \\(m\\) and \\(b\\), we can use x_variable to calculate y_variable for any value of x_variable. 6.4.5.1 Assumptions The standard linear regression (a least-squares regression) works best if both x_variable and y_variable are symmetrically distributed. 6.4.5.2 Statistical Test Calculating the coefficients \\(m\\) and \\(b\\) for a linear regression involves a call to lm() with a formula y_variable ~ x_variable (note this is slightly different than for correlation testing) and data = my_data_frame. For our example, the call would look like this: lm(totalprecip ~ meantemp, data = correlation_test_data) %&gt;% tidy() ## # A tibble: 2 x 5 ## term estimate std.error statistic p.value ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 (Intercept) 101.080256 5.453909 18.53354 8.134131e-33 ## 2 meantemp -1.438531 0.469326 -3.06510 2.855764e-03 The term column in the ouput refers to the name of the input column in the righthand side of the input formula, or “(Intercept)” for the intercept, and the estimate column refers to the coefficient itself. In the example, this means we can predict totalprecip using the (approximate) expression -1.44 * meantemp + 101.08. In practice, we want to use the predict() function to do this math for us (because if we change some code above that alters which observations are used to create the regression, it will change the coefficient and intercept, and any code that relies on the hard-coded version will be incorrect). This is a three step process: first, save the result of lm() to a variable, then create a data frame with a column that has the same name as x_variable, then use mutate() to create a new column with the predictions from predict(). Note that we use a special trick in mutate() to pass the entire data frame to the newdata argument of predict() (the . represents the whole data frame as opposed to any particular column, which we can refer to by name within mutate()). For our example, we might be interested in the predicted total monthly precipitation values when the mean monthly temperature is 5, 10, 15, and 20 degrees. model &lt;- lm(totalprecip ~ meantemp, data = climate_data) tibble(meantemp = c(5, 10, 15, 20)) %&gt;% mutate(totalprecip_predicted = predict(model, newdata = .)) ## # A tibble: 4 x 2 ## meantemp totalprecip_predicted ## &lt;dbl&gt; &lt;dbl&gt; ## 1 5 93.88760 ## 2 10 86.69494 ## 3 15 79.50229 ## 4 20 72.30963 6.5 Significant differences Tests for significant differences tests whether or not there is a significant difference among various groups of observations. Which test to use depends on whether or not the data are normally distributed, and how many groups exist. For our example, we will be looking at the diferences in mean temperature (meantemp) as grouped by several grouping variables (station_name, year, and month). 6.5.1 Test Data Tests for significant differences require a data frame with a column containing the values to test, and a column containing the variable to group by (usually contains strings like “group1”, “group2”, “group3”, etc.). It is often useful to keep other qualifying variables that give context to each observation, but are not required by the test. In our case, the column in climate_data that contains the values we are testing is meantemp, and the columns that contain the groups are station_name, year, and month. difference_test_data &lt;- climate_data %&gt;% select(station_name, year, month, meantemp) difference_test_data ## # A tibble: 96 x 4 ## station_name year month meantemp ## &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; ## 1 KENTVILLE CDA CS 2000 1 -4.2 ## 2 KENTVILLE CDA CS 2000 2 -2.6 ## 3 KENTVILLE CDA CS 2000 3 1.6 ## 4 KENTVILLE CDA CS 2000 4 6.4 ## 5 KENTVILLE CDA CS 2000 5 10.0 ## 6 KENTVILLE CDA CS 2000 6 16.4 ## 7 KENTVILLE CDA CS 2000 7 18.8 ## 8 KENTVILLE CDA CS 2000 8 19.2 ## 9 KENTVILLE CDA CS 2000 9 14.6 ## 10 KENTVILLE CDA CS 2000 10 9.9 ## # ... with 86 more rows 6.5.2 Graphical Test The graphic for significant difference tests is a plot with the grouping variable on the x-axis, and the value variable on the y-axis. This is generated using something like ggplot(my_data_frame, aes(x = group_column, y = value_column)) followed by geom_point() and/or geom_boxplot(). If the grouping variable is station_name, such a plot might look like this: ggplot(difference_test_data, aes(x = station_name, y = meantemp)) + geom_boxplot() ## Warning: Removed 1 rows containing non-finite values (stat_boxplot). For smaller numbers of observations, it may make sense to plot the values of the observations themselves using geom_point(). In the next example, the grouping variable is month (note that we have to use factor(month) in ggplot, because we are using a continuous variable as a grouping variable). ggplot(difference_test_data, aes(x = factor(month), y = meantemp)) + geom_point() ## Warning: Removed 1 rows containing missing values (geom_point). When there are a small number of observations in each group, it also may make sense to compute summary statistics and plot those instead of a boxplot or the observations themselves. This is done using stat_summary(), which by default displays a point with error bars plus or minus the standard error (the standard deviation divided by the square root of n). ggplot(difference_test_data, aes(x = factor(month), y = meantemp)) + stat_summary(size = 0.25) ## Warning: Removed 1 rows containing non-finite values (stat_summary). ## No summary function supplied, defaulting to `mean_se() Based on the graphic, you should be able to have a hunch as to whether or not one group of observations is significantly different than another group of observations (when grouped by station, it looks like there isn’t much difference in temperature, but when grouped by month, there is a clear difference). This is important, because it will make interpreting your results more intuitive and allows you to check for errors. 6.5.3 The t-test The t-test tests whether or not there is a significant difference between a value exactly two groups of observations (an ANOVA test can be used when there are more than two groups). We will be using this test to ascertain whether or not there is a significant difference in temperature when these observations are grouped by station (note that there are exactly two stations, Kentville and Greenwood). 6.5.3.1 Assumptions The t-test assumes that the two samples of data values are normally distributed and independent. 6.5.3.2 Statistical Test Performing the t-test uses a call to the t.test() function in the form t.test(value_column ~ group_column, data = my_data_frame), and a call to the tidy() function in the broom package to view the results in the form of a data frame. In the case of the Kentville/Greenwood climate data, the two tests look like this: t.test(meantemp ~ station_name, data = difference_test_data) %&gt;% tidy() ## # A tibble: 1 x 10 ## estimate estimate1 estimate2 statistic p.value parameter conf.low ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 0.06409574 7.4875 7.423404 0.03469596 0.9723966 92.9311 -3.604421 ## # ... with 3 more variables: conf.high &lt;dbl&gt;, method &lt;fctr&gt;, ## # alternative &lt;fctr&gt; Here the estimate column is the estimated difference between the means of the two groups, and the p.value column is the p-value, which represents the probability that there is no significant difference between the two groups (p=0.97). 6.5.4 Paired t-test Paired version of the t-test… 6.5.5 Wilcox Rank Sum/Mann-Whitney Test The Wilcox Rank Sum Test is… 6.5.6 The ANOVA test The ANOVA test tests whether or not there is a significant difference between a value using two or more groups of observations (an ANOVA test when there are only two groups is identical to a t-test). We will be using this test to ascertain whether or not there is a significant difference in mean monthly temperature when these observations are grouped by (1) year and (2) month. 6.5.6.1 Assumptions The ANOVA test assumes all samples of data values are normally distributed and independent. 6.5.6.2 Statistical Test Performing the ANOVA test uses a call to the aov() function in the form aov(value_column ~ group_column, data = my_data_frame), and a call to the tidy() function in the broom package to view the results in the form of a data frame. In the case of the Kentville/Greenwood climate data, the two tests look like this: aov(meantemp ~ year, data = difference_test_data) %&gt;% tidy() ## # A tibble: 2 x 6 ## term df sumsq meansq statistic p.value ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 year 1 3.482852 3.482852 0.04300005 0.8361786 ## 2 Residuals 93 7532.671464 80.996467 NA NA aov(meantemp ~ month, data = difference_test_data) %&gt;% tidy() ## # A tibble: 2 x 6 ## term df sumsq meansq statistic p.value ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 month 1 1057.750 1057.75038 15.18442 0.0001837213 ## 2 Residuals 93 6478.404 69.66026 NA NA Generally, the only column we care about in the output is the p.value, which is the probability that none of the groups of values are significantly different than any others. In the case of the Kentville/Greenwood climate data, there is a significant difference in temperature among months (p&lt;0.001), but no significant different in temperature among years (p=0.83). 6.5.7 Krustal-Wallis Rank Sum Test Krustal Wallis Test… 6.6 Summary Tutorial summary "]
]
